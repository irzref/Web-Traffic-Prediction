{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Step MLP Model\n",
    "\n",
    "references :\n",
    "\n",
    "- How to Develop Multilayer Perceptron Models for Time Series Forecasting\n",
    "\n",
    "  https://machinelearningmastery.com/how-to-develop-multilayer-perceptron-models-for-time-series-forecasting/\n",
    "  \n",
    "\n",
    "\n",
    "- Exploratory Configuration of a Multilayer Perceptron Network for Time Series Forecasting \n",
    "\n",
    "  https://machinelearningmastery.com/exploratory-configuration-multilayer-perceptron-network-time-series-forecasting/  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web traffic case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_df = read_csv('train_2.csv', nrows=1)\n",
    "wt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### select and transform dataframe row to sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe is converted to sequence or array format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the values without the page name\n",
    "\n",
    "def get_seq_by_row(input_df, row_num):\n",
    "    new_seq = np.delete(input_df.iloc[row_num].values, 0)\n",
    "    return new_seq\n",
    "\n",
    "wt_seq = get_seq_by_row(wt_df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wt_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### time lag parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the first 2 hyperparameter:\n",
    "    - time_step_lag : the number of NN input values  \n",
    "    - time_step_ahead : the number of NN output values, which means the number of days to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_lag = 7 # input of NN\n",
    "time_step_ahead = 30 # number of day to be predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The series is splitted into train and test set. \n",
    "\n",
    "The size of the train set is the original size subtracted by the time_step_head. The values are taken from the first values of the original series with the previouly mentioned size. The format of the train set is still a sequence.\n",
    "\n",
    "The test set is output in format of 2-dimention array with only one array entry, which holds the test set values. The values contains the input and the output values for the neural network and the size respectively is the same as time_step_lag and time_step_ahead. The input values are taken from the last values of the train set with already mentioned size and the output values are the remaining values of the original series after taking out the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_test_set(data_seq, time_step_lag, time_step_ahead):\n",
    "    train_seq = data_seq[:-time_step_ahead]\n",
    "    test_set = np.array([data_seq[-(time_step_lag + time_step_ahead):]])\n",
    "    return train_seq, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq, test = split_train_and_test_set(wt_seq, time_step_lag, time_step_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transform sequence to supervised format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the train set is converted into multiple sequences or array with each array has the size of combination of time_step_lag and time_step_ahead. \n",
    "\n",
    "Each sequence is formed by moving window scanning from first values of the train set series. \n",
    "\n",
    "The moving window has the size of the required array size and it shifts by 1 to form the next array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame a sequence as a supervised learning problem\n",
    "\n",
    "def timeseries_to_supervised(data, lag=1, stepahead=1):\n",
    "    df = DataFrame(data)\n",
    "    col_num = lag+stepahead\n",
    "    columns = [df.shift(i) for i in range(1, col_num)]\n",
    "    columns = list(reversed(columns))\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)    \n",
    "    return df.values[col_num - 1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wt_supervised = timeseries_to_supervised(train_seq, time_step_lag, time_step_ahead)\n",
    "wt_supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split train and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the reformated train set above, validation set is built by subtracting n number of array from the last entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_and_validation_set(dataset, num_of_test_set=12):\n",
    "    num_of_test_set = -1 * num_of_test_set\n",
    "    return dataset[0:num_of_test_set], dataset[num_of_test_set:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = split_train_and_validation_set(wt_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scale sequence value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the values are scaled into the range of -1 to 1. \n",
    "\n",
    "The scaler is built by fitting the train set on each value index or each variable.\n",
    "\n",
    "The scaler is then used to scale validation set values and test set values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale train and test data to [-1, 1]\n",
    "\n",
    "def scale(train, test):\n",
    "    \n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    \n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    \n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "def scale_with_scaler(scaler, data):\n",
    "    \n",
    "    # transform data\n",
    "    data = data.reshape(data.shape[0], data.shape[1])\n",
    "    data_scaled = scaler.transform(data)\n",
    "    \n",
    "    return data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train_scaled, validation_scaled = scale(train, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled = scale_with_scaler(scaler, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model has only one hidden layer with variable number of neuron and uses relu as activation function.\n",
    "\n",
    "the output layer uses the value of time_step_ahead to determine the number of output values.\n",
    "\n",
    "the loss function measures the MSE to calculate the error and optimizes the parameter using the adam optimizer.\n",
    "\n",
    "the model is packed in a function with input parameter of train set, batch size, number of epoch, neurons, time_step_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an MLP network to training data\n",
    "\n",
    "def fit_model(train, batch_size, nb_epoch, neurons, time_step_ahead):\n",
    "    \n",
    "    X, y = train[:, 0:-time_step_ahead], train[:, -time_step_ahead:]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # hidden layer\n",
    "    model.add(Dense(neurons, activation='relu', input_dim=X.shape[1]))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(time_step_ahead))\n",
    "    \n",
    "    # loss function\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    # model fitting\n",
    "    #model.fit(X, y, epochs=nb_epoch, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "    model.fit(X, y, epochs=nb_epoch, verbose=0, shuffle=False)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting the hyperparameter of the NN model and then training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 1000\n",
    "neurons = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = fit_model(train_scaled, batch_size, epochs, neurons, time_step_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction is done by calling the evaluate method, which uses the fitted model to predict the given input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, scaled_input, time_step_ahead):\n",
    "    \n",
    "    eval_input = scaled_input[:,0:-time_step_ahead]\n",
    "    \n",
    "    output = model.predict(eval_input)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = evaluate(model, train_scaled, time_step_ahead)\n",
    "train_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_output = evaluate(model, validation_scaled, time_step_ahead)\n",
    "validation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = evaluate(model, test_scaled, time_step_ahead)\n",
    "test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### invert scale the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the scaler above to invert back all the predicted values.\n",
    "\n",
    "the predicted values must be set together with the input values in order to be inverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse scaling for a forecasted value\n",
    "\n",
    "def invert_scale(scaler, X, yhat):    \n",
    "    new_row = [x for x in X] + [x for x in yhat]    \n",
    "    array = np.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    \n",
    "    return inverted[0, -len(yhat):]\n",
    "\n",
    "def invert_scale_prediction(scaler, scaled_set, scaled_output):\n",
    "    scaled_input = scaled_set[:,0:-time_step_ahead]\n",
    "    predictions = list()\n",
    "\n",
    "    for i in range(len(scaled_output)):\n",
    "        yhat = scaled_output[i]\n",
    "        X = scaled_input[i]\n",
    "\n",
    "        # invert scaling\n",
    "        yhat = invert_scale(scaler, X, yhat)    \n",
    "\n",
    "        # store forecast\n",
    "        predictions.append(yhat)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_unscaled_output = invert_scale_prediction(scaler, train_scaled, train_output)\n",
    "train_unscaled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_unscaled_output = invert_scale_prediction(scaler, validation_scaled, validation_output)\n",
    "validation_unscaled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unscaled_output = invert_scale_prediction(scaler, test_scaled, test_output)\n",
    "test_unscaled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(original, prediction, time_step_ahead):\n",
    "    \n",
    "    test_output = original[:,-time_step_ahead:]\n",
    "    rmse = sqrt(mean_squared_error(test_output, prediction))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = calculate_rmse(train, train_unscaled_output, time_step_ahead)\n",
    "\n",
    "print('Train RMSE: %.3f' % (train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_rmse = calculate_rmse(validation, validation_unscaled_output, time_step_ahead)\n",
    "\n",
    "print('Validation RMSE: %.3f' % (validation_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = calculate_rmse(test, test_unscaled_output, time_step_ahead)\n",
    "\n",
    "print('Test RMSE: %.3f' % (test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vary the time step lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "# time_step_lag = 2\n",
    "time_step_lag_array = np.arange(45,51)\n",
    "\n",
    "time_step_ahead = 30\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 2000\n",
    "neurons = 20\n",
    "\n",
    "\n",
    "\n",
    "train_rmse_array = []\n",
    "validation_rmse_array = []\n",
    "\n",
    "for time_step_lag in time_step_lag_array:\n",
    "\n",
    "    # split train - test set\n",
    "    train_seq, test = split_train_and_test_set(wt_seq, time_step_lag, time_step_ahead)\n",
    "    \n",
    "    # tranform data to NN input format\n",
    "    wt_supervised = timeseries_to_supervised(train_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "    # split train and test set\n",
    "    train, validation = split_train_and_validation_set(wt_supervised)\n",
    "\n",
    "    # scale dataset\n",
    "    scaler, train_scaled, validation_scaled = scale(train, validation)\n",
    "    \n",
    "    # fit model\n",
    "    model = fit_model(train_scaled, batch_size, epochs, neurons, time_step_ahead)\n",
    "\n",
    "    # evaluate train set\n",
    "    train_output = evaluate(model, train_scaled, time_step_ahead)\n",
    "    train_unscaled_output = invert_scale_prediction(scaler, train_scaled, train_output)\n",
    "    train_rmse = calculate_rmse(train, train_unscaled_output, time_step_ahead)\n",
    "    train_rmse_array.append(train_rmse)\n",
    "    \n",
    "    # evaluate test set\n",
    "    validation_output = evaluate(model, validation_scaled, time_step_ahead)\n",
    "    validation_unscaled_output = invert_scale_prediction(scaler, validation_scaled, validation_output)\n",
    "    validation_rmse = calculate_rmse(validation, validation_unscaled_output, time_step_ahead)\n",
    "    validation_rmse_array.append(validation_rmse)\n",
    "    \n",
    "    print('%d) TrainRMSE=%f, ValidationRMSE=%f' % (time_step_lag, train_rmse, validation_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([round(x,2) for x in train_rmse_array])\n",
    "print([round(x,2) for x in validation_rmse_array])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('time step lag')\n",
    "plt.plot(time_step_lag_array, train_rmse_array, '-', linewidth=1, color='orange', label='train RMSE')\n",
    "plt.plot(time_step_lag_array, validation_rmse_array, '-', linewidth=1, color='blue', label='validation RMSE')  \n",
    "plt.legend(loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vary the hidden layer neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "time_step_lag = 26\n",
    "# time_step_lag_array = np.arange(20,26)\n",
    "\n",
    "time_step_ahead = 30\n",
    "\n",
    "# split train - test set\n",
    "train_seq, test = split_train_and_test_set(wt_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 2000\n",
    "\n",
    "# neurons = 20\n",
    "neurons_array = np.arange(20,26)\n",
    "\n",
    "\n",
    "\n",
    "train_rmse_array = []\n",
    "validation_rmse_array = []\n",
    "\n",
    "for neurons in neurons_array:\n",
    "\n",
    "    # tranform data to NN input format\n",
    "    wt_supervised = timeseries_to_supervised(train_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "    # split train and test set\n",
    "    train, validation = split_train_and_validation_set(wt_supervised)\n",
    "\n",
    "    # scale dataset\n",
    "    scaler, train_scaled, validation_scaled = scale(train, validation)\n",
    "    \n",
    "    # fit model\n",
    "    model = fit_model(train_scaled, batch_size, epochs, neurons, time_step_ahead)\n",
    "\n",
    "    # evaluate train set\n",
    "    train_output = evaluate(model, train_scaled, time_step_ahead)\n",
    "    train_unscaled_output = invert_scale_prediction(scaler, train_scaled, train_output)\n",
    "    train_rmse = calculate_rmse(train, train_unscaled_output, time_step_ahead)\n",
    "    train_rmse_array.append(train_rmse)\n",
    "    \n",
    "    # evaluate test set\n",
    "    validation_output = evaluate(model, validation_scaled, time_step_ahead)\n",
    "    validation_unscaled_output = invert_scale_prediction(scaler, validation_scaled, validation_output)\n",
    "    validation_rmse = calculate_rmse(validation, validation_unscaled_output, time_step_ahead)\n",
    "    validation_rmse_array.append(validation_rmse)\n",
    "    \n",
    "    print('%d) TrainRMSE=%f, ValidationRMSE=%f' % (neurons, train_rmse, validation_rmse))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('time step lag')\n",
    "plt.plot(time_step_lag_array, train_rmse_array, '-', linewidth=1, color='orange', label='train RMSE')\n",
    "plt.plot(time_step_lag_array, validation_rmse_array, '-', linewidth=1, color='blue', label='validation RMSE')  \n",
    "plt.legend(loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE MAIN PART OF BUILDING NN MODEL FOR COMPARING WITH ARIMA\n",
    "## Using smoothed dataset from R \n",
    "\n",
    "the following code is the main part to build model and calculate the prediction, which then is compared to the ARIMA model.\n",
    "\n",
    "However, this will require the defined methods above to be executed first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read dataset from R\n",
    "\n",
    "In R the dataset is already smoothed using moving average.\n",
    "\n",
    "The dataset in R is exported to CSV File and read here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wt_df = read_csv('data.csv')\n",
    "wt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### take only the moving average 30 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the values smoothed by moving average with frequency of 30 are going to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_seq = wt_df['Clicks.MA30'].dropna().values\n",
    "wt_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optimizing model by the number of time step lag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- time step lag value is varied to find the best value for time_step_lag \n",
    "- the procedures are\n",
    "    - initialzing the parameter\n",
    "    - loop through the all values of time_step_lag\n",
    "    - in the loop\n",
    "        - train and test set are spitted\n",
    "        - the train set is converted to input-output array format\n",
    "        - the train set is splitted into train and validation set format\n",
    "        - the values are scaled\n",
    "        - the model is fitted\n",
    "        - the prediction is made\n",
    "        - the values are inverted back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "#time_step_lag = 26\n",
    "time_step_lag_array = np.arange(5,81,5)\n",
    "\n",
    "time_step_ahead = 30\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 2000\n",
    "\n",
    "neurons = 25\n",
    "#neurons_array = np.arange(25,30)\n",
    "\n",
    "\n",
    "\n",
    "train_rmse_array = []\n",
    "validation_rmse_array = []\n",
    "\n",
    "for time_step_lag in time_step_lag_array:\n",
    "    \n",
    "    # split into train - test set\n",
    "    train_seq, test = split_train_and_test_set(wt_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "    # tranform data to NN input format\n",
    "    wt_supervised = timeseries_to_supervised(train_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "    # split train and test set\n",
    "    train, validation = split_train_and_validation_set(wt_supervised)\n",
    "\n",
    "    # scale dataset\n",
    "    scaler, train_scaled, validation_scaled = scale(train, validation)\n",
    "    \n",
    "    # fit model\n",
    "    model = fit_model(train_scaled, batch_size, epochs, neurons, time_step_ahead)\n",
    "\n",
    "    # evaluate train set\n",
    "    train_output = evaluate(model, train_scaled, time_step_ahead)\n",
    "    train_unscaled_output = invert_scale_prediction(scaler, train_scaled, train_output)\n",
    "    train_rmse = calculate_rmse(train, train_unscaled_output, time_step_ahead)\n",
    "    train_rmse_array.append(train_rmse)\n",
    "    \n",
    "    # evaluate test set\n",
    "    validation_output = evaluate(model, validation_scaled, time_step_ahead)\n",
    "    validation_unscaled_output = invert_scale_prediction(scaler, validation_scaled, validation_output)\n",
    "    validation_rmse = calculate_rmse(validation, validation_unscaled_output, time_step_ahead)\n",
    "    validation_rmse_array.append(validation_rmse)\n",
    "    \n",
    "    print('%d) TrainRMSE=%f, ValidationRMSE=%f' % (time_step_lag, train_rmse, validation_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save the validation result in csv for time step lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_res = pd.DataFrame({'time_step_lag': time_step_lag_array, 'validationRMSE': validation_rmse_array})\n",
    "validation_res.to_csv('../ml2/data/validation-time-step-lag.csv')\n",
    "validation_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optimizing model by the number of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the number of neuron is varied to find the best number of neuron\n",
    "- the procedures are\n",
    "    - initialzing the parameter\n",
    "    - train and test set are spitted\n",
    "    - loop through the all values of number of neuron    \n",
    "    - in the loop\n",
    "        - the train set is converted to input-output array format\n",
    "        - the train set is splitted into train and validation set format\n",
    "        - the values are scaled\n",
    "        - the model is fitted\n",
    "        - the prediction is made\n",
    "        - the values are inverted back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "time_step_lag = 50\n",
    "\n",
    "time_step_ahead = 30\n",
    "\n",
    "# split train - test set\n",
    "train_seq, test = split_train_and_test_set(wt_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 2000\n",
    "\n",
    "# neurons = 20\n",
    "neurons_array = np.arange(5,51,5)\n",
    "\n",
    "\n",
    "\n",
    "train_rmse_array = []\n",
    "validation_rmse_array = []\n",
    "\n",
    "for neurons in neurons_array:\n",
    "\n",
    "    # tranform data to NN input format\n",
    "    wt_supervised = timeseries_to_supervised(train_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "    # split train and test set\n",
    "    train, validation = split_train_and_validation_set(wt_supervised)\n",
    "\n",
    "    # scale dataset\n",
    "    scaler, train_scaled, validation_scaled = scale(train, validation)\n",
    "    \n",
    "    # fit model\n",
    "    model = fit_model(train_scaled, batch_size, epochs, neurons, time_step_ahead)\n",
    "\n",
    "    # evaluate train set\n",
    "    train_output = evaluate(model, train_scaled, time_step_ahead)\n",
    "    train_unscaled_output = invert_scale_prediction(scaler, train_scaled, train_output)\n",
    "    train_rmse = calculate_rmse(train, train_unscaled_output, time_step_ahead)\n",
    "    train_rmse_array.append(train_rmse)\n",
    "    \n",
    "    # evaluate test set\n",
    "    validation_output = evaluate(model, validation_scaled, time_step_ahead)\n",
    "    validation_unscaled_output = invert_scale_prediction(scaler, validation_scaled, validation_output)\n",
    "    validation_rmse = calculate_rmse(validation, validation_unscaled_output, time_step_ahead)\n",
    "    validation_rmse_array.append(validation_rmse)\n",
    "    \n",
    "    print('%d) TrainRMSE=%f, ValidationRMSE=%f' % (neurons, train_rmse, validation_rmse))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save the validation result in csv for neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_res = pd.DataFrame({'neurons': neurons_array, 'validationRMSE': validation_rmse_array})\n",
    "validation_res.to_csv('../ml2/data/validation-neuron.csv')\n",
    "validation_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build model with best parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best parameters based on the above grid search are use to build model.\n",
    "\n",
    "the model is fitted using the train set including the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step_lag = 50\n",
    "\n",
    "time_step_ahead = 30\n",
    "\n",
    "# split into train - test set\n",
    "train_seq, test = split_train_and_test_set(wt_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 2000\n",
    "neurons = 45\n",
    "\n",
    "# tranform data to NN input format\n",
    "wt_supervised = timeseries_to_supervised(train_seq, time_step_lag, time_step_ahead)\n",
    "\n",
    "# split train and test set\n",
    "train, validation = split_train_and_validation_set(wt_supervised)\n",
    "\n",
    "# scale dataset\n",
    "scaler, train_scaled, validation_scaled = scale(wt_supervised, validation)\n",
    "\n",
    "# fit model\n",
    "model = fit_model(train_scaled, batch_size, epochs, neurons, time_step_ahead)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scaled = scale_with_scaler(scaler, test)\n",
    "test_output = evaluate(model, test_scaled, time_step_ahead)\n",
    "test_unscaled_output = invert_scale_prediction(scaler, test_scaled, test_output)\n",
    "test_rmse = calculate_rmse(test, test_unscaled_output, time_step_ahead)\n",
    "\n",
    "print('Test RMSE: %.3f' % (test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save test result in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_res = pd.DataFrame({'actual': test[0,-time_step_ahead:], 'prediction': test_unscaled_output[0]})\n",
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res.to_csv('../ml2/data/test-lag-50-neuron-45.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
